{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dandamudi-geeta/NaturalLanguageProcessing/blob/main/Geeta_Priya_512(NLP_Lab1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_zHvoqFULge"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, TweetTokenizer, RegexpTokenizer\n",
        "from nltk.tokenize import MWETokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from gensim.models import Word2Vec\n",
        "from keras.preprocessing.text import text_to_word_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eAqumQAUpNp"
      },
      "outputs": [],
      "source": [
        "paragraph=\"Dragons, often depicted as fearsome and powerful creatures 🐉🔥, have captured the imagination of people for centuries. With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends. Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness. In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes. The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.  \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1A8vnaBUpW4",
        "outputId": "a1262730-8dd5-43d9-85fe-3787b28ac78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CPCWew1U0Kw"
      },
      "source": [
        "**Word Tokenization**\n",
        "\n",
        "Breaks down text into individual words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2azfbMgjUpaF",
        "outputId": "3369e81a-8924-4a9f-bc07-9df14dd20025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ],
      "source": [
        "print(word_tokenize(paragraph))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udpEkyn5Updl"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKJJrufsUpgu"
      },
      "outputs": [],
      "source": [
        "# Process the paragraph using spaCy\n",
        "doc = nlp(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-zATEYcUpjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a34a6d1-0429-4ba2-d9dd-ff4f831104cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉', '🔥', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.', ' ']\n",
            "Dragons\n",
            ",\n",
            "often\n",
            "depicted\n",
            "as\n",
            "fearsome\n",
            "and\n",
            "powerful\n",
            "creatures\n",
            "🐉\n",
            "🔥\n",
            ",\n",
            "have\n",
            "captured\n",
            "the\n",
            "imagination\n",
            "of\n",
            "people\n",
            "for\n",
            "centuries\n",
            ".\n",
            "With\n",
            "their\n",
            "towering\n",
            "presence\n",
            "and\n",
            "scaly\n",
            "bodies\n",
            ",\n",
            "dragons\n",
            "have\n",
            "been\n",
            "the\n",
            "focus\n",
            "of\n",
            "countless\n",
            "myths\n",
            "and\n",
            "legends\n",
            ".\n",
            "Despite\n",
            "their\n",
            "majestic\n",
            "appearance\n",
            ",\n",
            "dragons\n",
            "do\n",
            "n't\n",
            "always\n",
            "fit\n",
            "the\n",
            "stereotype\n",
            "of\n",
            "being\n",
            "purely\n",
            "destructive\n",
            ";\n",
            "in\n",
            "some\n",
            "stories\n",
            ",\n",
            "they\n",
            "exhibit\n",
            "wisdom\n",
            "and\n",
            "protectiveness\n",
            ".\n",
            "In\n",
            "popular\n",
            "culture\n",
            ",\n",
            "dragons\n",
            "have\n",
            "been\n",
            "both\n",
            "feared\n",
            "and\n",
            "revered\n",
            ",\n",
            "often\n",
            "portrayed\n",
            "as\n",
            "guardians\n",
            "of\n",
            "treasure\n",
            "or\n",
            "formidable\n",
            "adversaries\n",
            "to\n",
            "brave\n",
            "heroes\n",
            ".\n",
            "The\n",
            "fascination\n",
            "with\n",
            "dragons\n",
            "persists\n",
            ",\n",
            "with\n",
            "their\n",
            "enigmatic\n",
            "nature\n",
            "and\n",
            "mythical\n",
            "allure\n",
            "continuing\n",
            "to\n",
            "captivate\n",
            "the\n",
            "hearts\n",
            "and\n",
            "minds\n",
            "of\n",
            "many\n",
            ".\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# Extract words from the processed document\n",
        "tokens = [token.text for token in doc]\n",
        "\n",
        "# Display the result\n",
        "print(tokens)\n",
        "for i in range(0,len(tokens)):\n",
        "  print(tokens[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WzBW-CLUpmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62926a4-35a2-48aa-95b1-8b430ad7305f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "blob = TextBlob(paragraph)\n",
        "\n",
        "# Tokenize the paragraph into words\n",
        "tokens = blob.words\n",
        "\n",
        "# Display the result\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence Tokenization:**\n",
        "splitting a text into sentences.\n",
        "we can use NLTK LIBRARY"
      ],
      "metadata": {
        "id": "c24c0e0PazuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65zHc03NUppd"
      },
      "outputs": [],
      "source": [
        "K=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKAwSRoSUpsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3b132b-68d1-4619-f210-7c86f88a67bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dragons, often depicted as fearsome and powerful creatures 🐉🔥, have captured the imagination of people for centuries.\n",
            "With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends.\n",
            "Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness.\n",
            "In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes.\n",
            "The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.\n"
          ]
        }
      ],
      "source": [
        "K=sent_tokenize(paragraph)\n",
        "L=len(K)\n",
        "for i in range(0,L):\n",
        "  print(K[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izvxeep3UpvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "931bf4d4-cfa1-4b29-8613-46de13838b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons, often depicted as fearsome and powerful creatures 🐉🔥, have captured the imagination of people for centuries.', 'With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends.', \"Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness.\", 'In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes.', 'The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.  ']\n"
          ]
        }
      ],
      "source": [
        "# Process the paragraph using spaCy\n",
        "doc = nlp(paragraph)\n",
        "\n",
        "# Extract sentences from the processed document\n",
        "sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "# Display the result\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aZSxZBaUpyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0c8e82-e081-47e7-b597-0f534ec3eaac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence(\"Dragons, often depicted as fearsome and powerful creatures 🐉🔥, have captured the imagination of people for centuries.\"), Sentence(\"With their towering presence and scaly bodies, dragons have been the focus of countless myths and legends.\"), Sentence(\"Despite their majestic appearance, dragons don't always fit the stereotype of being purely destructive; in some stories, they exhibit wisdom and protectiveness.\"), Sentence(\"In popular culture, dragons have been both feared and revered, often portrayed as guardians of treasure or formidable adversaries to brave heroes.\"), Sentence(\"The fascination with dragons persists, with their enigmatic nature and mythical allure continuing to captivate the hearts and minds of many.\")]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the paragraph into sentences\n",
        "sentences = blob.sentences\n",
        "\n",
        "# Display the result\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yno30akyUp08"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import WordPunctTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxdGgpoTUp4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109efd41-ba5b-4b14-d75c-274ad311fd6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥,', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'don', \"'\", 't', 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = WordPunctTokenizer()\n",
        "tokens = tokenizer.tokenize(paragraph)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the paragraph based on punctuation\n",
        "tokens = blob.words\n",
        "\n",
        "# Display the result\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0A-Z9VsbI1m",
        "outputId": "1eca4729-f876-4f36-9f48-a8cdd4219c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treebank Word Tokenizer**"
      ],
      "metadata": {
        "id": "vgYzABFMbNgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treebank Word Tokenizer\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "treebank_tokens = treebank_tokenizer.tokenize(paragraph)\n",
        "print(\"\\nTreebank Word Tokenizer:\", treebank_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AmTEJUubKrG",
        "outputId": "fa3858b6-9756-4c38-d55a-49f2d61ebce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Treebank Word Tokenizer: ['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tweet Tokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenizer.tokenize(paragraph)\n",
        "\n",
        "print(\"\\nTweet Tokenizer:\", tweet_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEm2H76qbLE3",
        "outputId": "1078d9ac-ca83-4d79-ec57-29d89888dd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tweet Tokenizer: ['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉', '🔥', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', \"don't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Word Expression Tokenizer\n",
        "mwe_tokenizer = MWETokenizer([('majestic', 'creatures')])\n",
        "mwe_tokens = mwe_tokenizer.tokenize(tokens)\n",
        "print(\"\\nMulti-Word Expression Tokenizer:\", mwe_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6NFoyoBbLWo",
        "outputId": "2e1f552c-df50-411c-e22e-f01f76523019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Word Expression Tokenizer: ['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextBlob Word Tokenize\n",
        "textblob_tokens = TextBlob(paragraph).words\n",
        "print(\"\\nTextBlob Word Tokenize:\", textblob_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVhlhLr1bYu-",
        "outputId": "4123682a-65cf-45c5-c4eb-fdb15a02a344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TextBlob Word Tokenize: ['Dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'Despite', 'their', 'majestic', 'appearance', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'In', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'The', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spaCy Tokenizer\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spaCy_tokens = [token.text for token in nlp(paragraph)]\n",
        "print(\"\\nspaCy Tokenizer:\", spaCy_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MQgvtSdbaw7",
        "outputId": "2f4b1007-8d00-4c50-daba-677906d82500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Tokenizer: ['Dragons', ',', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉', '🔥', ',', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', '.', 'With', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', ',', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', '.', 'Despite', 'their', 'majestic', 'appearance', ',', 'dragons', 'do', \"n't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', ';', 'in', 'some', 'stories', ',', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', '.', 'In', 'popular', 'culture', ',', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', ',', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', '.', 'The', 'fascination', 'with', 'dragons', 'persists', ',', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many', '.', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim Word Tokenizer\n",
        "gensim_model = Word2Vec(sentences=[tokens], min_count=1)\n",
        "gensim_tokens = list(gensim_model.wv.index_to_key)\n",
        "print(\"\\nGensim Word Tokenizer:\", gensim_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n1Hyld5bcaY",
        "outputId": "fe0c3f77-6427-4fa9-bd2c-86bf8a9eba1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gensim Word Tokenizer: ['and', 'of', 'dragons', 'the', 'have', 'their', 'often', 'as', 'been', 'with', 'to', 'myths', 'focus', 'countless', 'many', 'legends', 'scaly', 'Despite', 'majestic', 'appearance', 'do', \"n't\", 'bodies', 'centuries', 'presence', 'towering', 'With', 'fit', 'for', 'people', 'imagination', 'captured', '🐉🔥', 'creatures', 'powerful', 'fearsome', 'depicted', 'always', 'being', 'stereotype', 'minds', 'or', 'formidable', 'adversaries', 'brave', 'heroes', 'The', 'fascination', 'persists', 'enigmatic', 'nature', 'mythical', 'allure', 'continuing', 'captivate', 'hearts', 'treasure', 'guardians', 'portrayed', 'exhibit', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'wisdom', 'revered', 'protectiveness', 'In', 'popular', 'culture', 'both', 'feared', 'Dragons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization with Keras\n",
        "keras_tokens = text_to_word_sequence(paragraph)\n",
        "print(\"\\nTokenization with Keras:\", keras_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1j1TPuqbeqK",
        "outputId": "a09506d2-5e7f-4da8-a4a4-9e5b079e1a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenization with Keras: ['dragons', 'often', 'depicted', 'as', 'fearsome', 'and', 'powerful', 'creatures', '🐉🔥', 'have', 'captured', 'the', 'imagination', 'of', 'people', 'for', 'centuries', 'with', 'their', 'towering', 'presence', 'and', 'scaly', 'bodies', 'dragons', 'have', 'been', 'the', 'focus', 'of', 'countless', 'myths', 'and', 'legends', 'despite', 'their', 'majestic', 'appearance', 'dragons', \"don't\", 'always', 'fit', 'the', 'stereotype', 'of', 'being', 'purely', 'destructive', 'in', 'some', 'stories', 'they', 'exhibit', 'wisdom', 'and', 'protectiveness', 'in', 'popular', 'culture', 'dragons', 'have', 'been', 'both', 'feared', 'and', 'revered', 'often', 'portrayed', 'as', 'guardians', 'of', 'treasure', 'or', 'formidable', 'adversaries', 'to', 'brave', 'heroes', 'the', 'fascination', 'with', 'dragons', 'persists', 'with', 'their', 'enigmatic', 'nature', 'and', 'mythical', 'allure', 'continuing', 'to', 'captivate', 'the', 'hearts', 'and', 'minds', 'of', 'many']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why do we need Tokenization**\n",
        "\n",
        "Tokenization is the first step in any NLP pipeline. It has an important effect on the rest of your pipeline. A tokenizer breaks unstructured data and natural language text into chunks of information that can be considered as discrete elements. The token occurrences in a document can be used directly as a vector representing that document.\n",
        "\n",
        "Tokenization is essential for various purposes in different domains such as finance, cybersecurity, and natural language processing. Here are a few reasons why tokenization is needed:\n",
        "\n",
        "1. Security: In the context of financial transactions, tokenization replaces sensitive data such as credit card numbers with non-sensitive data called tokens. These tokens are useless to hackers if intercepted, adding an extra layer of security to the transaction process.\n",
        "\n",
        "2. Data Privacy: In the realm of cybersecurity, tokenization helps protect sensitive information by replacing it with non-sensitive tokens. This aids in compliance with data privacy regulations such as the GDPR and the HIPAA.\n",
        "\n",
        "3. Information Retrieval: In natural language processing, tokenization is used to break down natural language text into smaller units called tokens. This enables the analysis and processing of textual data for tasks such as sentiment analysis, named entity recognition, and language modeling.\n",
        "\n",
        "4. Efficiency in Processing: Tokenization helps in efficiently handling and processing textual data in machine learning and data analysis tasks. By breaking down text into tokens, it facilitates operations such as stemming, lemmatization, and overall text analysis.\n",
        "\n",
        "\n",
        "*  Tokenization is crucial for enhancing security, privacy,and efficiency in various domains where sensitive data needs to be protected or where textual data needs to be processed effectively.  \n"
      ],
      "metadata": {
        "id": "DdnpmvW0bmUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Tokenization is the process of breaking down a text into smaller units called tokens. These tokens can be words, subwords, or even characters, depending on the level of granularity you need. Tokenization is a fundamental step in natural language processing (NLP) and is crucial for various language-related tasks such as text analysis, machine translation, sentiment analysis.\n",
        "* In the context of word tokenization, the goal is to split a sentence or a piece of text into individual words. For example, the sentence \"Tokenization is important for NLP\" would be tokenized into the following words: [\"Tokenization\", \"is\", \"important\", \"for\", \"NLP\"].\n",
        "\n",
        "*  Sentence tokenization involves breaking down a longer text into its constituent sentences. This process is essential when dealing with tasks that require understanding the structure and meaning of individual sentences.\n",
        "* Tokenization helps convert raw text into a format that can be easily processed and analyzed by machines or algorithms. It serves as a foundational step in many NLP applications by providing a structured representation of textual data."
      ],
      "metadata": {
        "id": "WNU9sHlicFIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Tokenization can separate sentences, words, characters,or subwords. When we split the text into sentences, we call it sentence tokenization. For words, we call it word tokenization.\n",
        "\n",
        "**Different tools for tokenization**\n",
        "\n",
        "Although tokenization in Python may be simple, we know that it’s the foundation to develop good models and help us understand the text corpus. This section will list a few tools available for tokenizing text content like NLTK, TextBlob, spacy, Gensim, and Keras.\n",
        "\n",
        "**White Space Tokenization**\n",
        "\n",
        "The simplest way to tokenize text is to use whitespace within a string as the “delimiter” of words. This can be accomplished with Python’s split function, which is available on all string object instances as well as on the string built-in class itself. You can change the separator any way you need.\n",
        "\n",
        "**NLTK Word Tokenize**\n",
        "\n",
        "NLTK (Natural Language Toolkit) is an open-source Python library for Natural Language Processing. It has easy-to-use interfaces for over 50 corpora and lexical resources such as WordNet, along with a set of text processing libraries for classification, tokenization, stemming, and tagging.\n",
        "\n",
        "You can easily tokenize the sentences and words of the text with the tokenize module of NLTK.\n",
        "\n",
        "**Punctuation-based tokenizer**\n",
        "\n",
        "\n",
        "This tokenizer splits the sentences into words based on whitespaces and punctuations.\n",
        "\n",
        "**Treebank Word tokenizer**\n",
        "\n",
        "This tokenizer incorporates a variety of common rules for english word tokenization. It separates phrase-terminating punctuation like (?!.;,) from adjacent tokens and retains decimal numbers as a single token. Besides, it contains rules for English contractions.\n",
        "\n",
        "**Tweet tokenizer**\n",
        "\n",
        "When we want to apply tokenization in text data like tweets, the tokenizers mentioned above can’t produce practical tokens. Through this issue, NLTK has a rule based tokenizer special for tweets. We can split emojis into different words if we need them for tasks like sentiment analysis.\n",
        "\n",
        "**MWET tokenizer**\n",
        "\n",
        "NLTK’s multi-word expression tokenizer (MWETokenizer) provides a function add_mwe() that allows the user to enter multiple word expressions before using the tokenizer on the text. More simply, it can merge multi-word expressions into single tokens.\n",
        "\n",
        "**TextBlob Word Tokenize**\n",
        "\n",
        "TextBlob is a Python library for processing textual data. It provides a consistent API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
        "\n",
        "**spaCy Tokenizer**\n",
        "\n",
        "SpaCy is an open-source Python library that parses and understands large volumes of text. With available models catering to specific languages (English, French, German, etc.), it handles NLP tasks with the most efficient implementation of common algorithms.\n",
        "\n",
        "SpaCy tokenizer provides the flexibility to specify special tokens that don’t need to be segmented, or need to be segmented using special rules for each language, for example punctuation at the end of a sentence should be split off – whereas “U.K.” should remain one token.\n",
        "\n",
        "**Gensim word tokenizer**\n",
        "\n",
        "Gensim is a Python library for topic modeling, document indexing, and similarity retrieval with large corpora. The target audience is the natural language processing (NLP) and information retrieval (IR) community. It offers utility functions for tokenization.\n",
        "\n",
        "**Tokenization with Keras**\n",
        "\n",
        "Keras open-source library is one of the most reliable deep learning frameworks. To perform tokenization we use: text_to_word_sequence method from the Class Keras.preprocessing.text class. The great thing about Keras is converting the alphabet in a lower case before tokenizing it, which can be quite a time-saver."
      ],
      "metadata": {
        "id": "BXoniEa-cReh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}